{"file_contents":{"run.py":{"content":"#!/usr/bin/env python3\n\"\"\"\nProduction runner for Smart Resume Analyzer\nUse this for deployment instead of app.py\n\"\"\"\n\nimport os\nimport sys\nfrom app import app\n\nif __name__ == '__main__':\n    # Production configuration\n    debug_mode = os.environ.get('DEBUG', 'False').lower() == 'true'\n    host = os.environ.get('HOST', '0.0.0.0')\n    port = int(os.environ.get('PORT', 5000))\n    \n    print(\"üöÄ Starting Smart Resume Analyzer (Production Mode)\")\n    print(f\"üìç Host: {host}\")\n    print(f\"üî¢ Port: {port}\")\n    print(f\"üêõ Debug: {debug_mode}\")\n    print(\"=\" * 50)\n    \n    app.run(\n        host=host,\n        port=port,\n        debug=debug_mode,\n        threaded=True\n    )","size_bytes":680},"utils/parser.py":{"content":"import PyPDF2\nfrom pdfminer.high_level import extract_text as pdfminer_extract\nfrom docx import Document\nimport re\nfrom datetime import datetime\n\nclass ResumeParser:\n    def extract_text(self, file_path, file_ext):\n        \"\"\"Extract text from PDF or DOCX files with fallback methods\"\"\"\n        try:\n            if file_ext == '.pdf':\n                # Try pdfminer first (better for some PDFs)\n                try:\n                    text = pdfminer_extract(file_path)\n                    if text and len(text.strip()) > 100:\n                        return text\n                except Exception as e:\n                    print(f\"pdfminer failed: {e}, trying PyPDF2...\")\n                \n                # Fallback to PyPDF2\n                try:\n                    with open(file_path, 'rb') as file:\n                        reader = PyPDF2.PdfReader(file)\n                        text = \"\"\n                        for page in reader.pages:\n                            page_text = page.extract_text()\n                            if page_text:\n                                text += page_text + \"\\n\"\n                        return text\n                except Exception as e:\n                    print(f\"PyPDF2 failed: {e}\")\n                    return f\"Error reading PDF: {str(e)}\"\n                    \n            elif file_ext == '.docx':\n                try:\n                    doc = Document(file_path)\n                    text = \"\"\n                    for paragraph in doc.paragraphs:\n                        if paragraph.text:\n                            text += paragraph.text + \"\\n\"\n                    return text\n                except Exception as e:\n                    return f\"Error reading DOCX: {str(e)}\"\n            else:\n                return f\"Unsupported file type: {file_ext}\"\n                \n        except Exception as e:\n            return f\"Error extracting text: {str(e)}\"\n    \n    def parse_personal_info(self, text):\n        \"\"\"Extract personal information from resume text\"\"\"\n        info = {'name': '', 'email': '', 'phone': '', 'location': ''}\n        \n        if not text:\n            return info\n        \n        # Extract email\n        email_pattern = r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'\n        emails = re.findall(email_pattern, text)\n        if emails:\n            info['email'] = emails[0]\n        \n        # Extract phone numbers (international format support)\n        phone_patterns = [\n            r'(\\+?\\d{1,3}[-.\\s]?)?\\(?\\d{3}\\)?[-.\\s]?\\d{3}[-.\\s]?\\d{4}',  # US format\n            r'\\+?[\\d\\s-]{10,}',  # International format\n            r'\\(\\d{3}\\)\\s*\\d{3}[-.\\s]?\\d{4}'  # (123) 456-7890\n        ]\n        \n        for pattern in phone_patterns:\n            phones = re.findall(pattern, text)\n            if phones:\n                # Take the first phone number found\n                phone = phones[0]\n                if isinstance(phone, tuple):\n                    phone = ''.join(phone)\n                info['phone'] = phone.strip()\n                break\n        \n        # Extract name (improved heuristic)\n        lines = text.split('\\n')\n        for i, line in enumerate(lines[:15]):  # Check first 15 lines\n            line = line.strip()\n            if (len(line) > 2 and len(line) < 50 and \n                not any(char.isdigit() for char in line) and\n                '@' not in line and \n                'http' not in line.lower() and\n                not line.lower().startswith('experience') and\n                not line.lower().startswith('education') and\n                not line.lower().startswith('skills') and\n                len(line.split()) >= 2 and len(line.split()) <= 4):\n                \n                # Additional check: next line often contains title\n                if i + 1 < len(lines) and len(lines[i + 1].strip()) > 0:\n                    info['name'] = line\n                    break\n        \n        # Extract location (simple keyword matching)\n        location_keywords = [\n            'new york', 'london', 'san francisco', 'chicago', 'austin', \n            'remote', 'hybrid', 'boston', 'seattle', 'los angeles',\n            'toronto', 'sydney', 'berlin', 'paris', 'tokyo'\n        ]\n        \n        text_lower = text.lower()\n        for location in location_keywords:\n            if location in text_lower:\n                info['location'] = location.title()\n                break\n        \n        return info\n    \n    def extract_skills(self, text):\n        \"\"\"Extract skills from resume text using comprehensive skill database\"\"\"\n        if not text:\n            return {}\n        \n        skills_db = {\n            'Programming': [\n                'python', 'java', 'javascript', 'c++', 'c#', 'ruby', 'php', 'swift', \n                'kotlin', 'go', 'rust', 'typescript', 'scala', 'r', 'matlab'\n            ],\n            'Web Development': [\n                'html', 'css', 'react', 'angular', 'vue', 'django', 'flask', \n                'node.js', 'express', 'spring', 'laravel', 'bootstrap', 'jquery'\n            ],\n            'Database': [\n                'sql', 'mysql', 'postgresql', 'mongodb', 'redis', 'oracle', \n                'sqlite', 'cassandra', 'dynamodb', 'firebase'\n            ],\n            'Cloud & DevOps': [\n                'aws', 'azure', 'gcp', 'docker', 'kubernetes', 'jenkins', \n                'terraform', 'ansible', 'git', 'ci/cd', 'github', 'gitlab'\n            ],\n            'AI/ML': [\n                'machine learning', 'deep learning', 'tensorflow', 'pytorch', \n                'nlp', 'computer vision', 'neural networks', 'scikit-learn',\n                'opencv', 'keras'\n            ],\n            'Data Science': [\n                'pandas', 'numpy', 'r', 'matplotlib', 'seaborn', 'tableau', \n                'power bi', 'excel', 'statistics', 'analytics'\n            ],\n            'Soft Skills': [\n                'leadership', 'communication', 'teamwork', 'problem solving', \n                'project management', 'agile', 'scrum', 'time management',\n                'critical thinking', 'creativity', 'adaptability'\n            ],\n            'Tools & Platforms': [\n                'jira', 'confluence', 'slack', 'teams', 'zoom', 'notion',\n                'trello', 'asana', 'word', 'excel', 'powerpoint', 'outlook'\n            ]\n        }\n        \n        found_skills = {}\n        text_lower = text.lower()\n        \n        for category, skills in skills_db.items():\n            found_skills[category] = []\n            for skill in skills:\n                # Use word boundaries to avoid partial matches\n                pattern = r'\\b' + re.escape(skill) + r'\\b'\n                if re.search(pattern, text_lower, re.IGNORECASE):\n                    found_skills[category].append(skill)\n        \n        return found_skills\n    \n    def extract_experience(self, text):\n        \"\"\"Extract work experience information\"\"\"\n        experience = {\n            'total_years': 0,\n            'positions': [],\n            'companies': []\n        }\n        \n        if not text:\n            return experience\n        \n        # Extract years from text\n        year_pattern = r'\\b(19|20)\\d{2}\\b'\n        years = [int(year) for year in re.findall(year_pattern, text)]\n        \n        if years:\n            # Calculate approximate experience (max year - min year)\n            if len(years) >= 2:\n                experience['total_years'] = max(years) - min(years)\n            else:\n                experience['total_years'] = 0\n            \n            # Simple heuristic: if only one year found, assume 1+ years\n            if len(years) == 1 and years[0] <= datetime.now().year:\n                experience['total_years'] = datetime.now().year - years[0]\n        \n        # Extract job titles and companies (basic pattern matching)\n        job_patterns = [\n            r'(?i)(.*?)\\s*(?:at|@|\\|)\\s*(.*?)(?:\\n|$)',\n            r'(?i)(.*?)\\s*-\\s*(.*?)(?:\\n|$)',\n            r'(?i)(senior|junior|lead)?\\s*([a-z]+)\\s*(?:developer|engineer|analyst|manager)'\n        ]\n        \n        for pattern in job_patterns:\n            matches = re.findall(pattern, text, re.IGNORECASE)\n            for match in matches:\n                if len(match) == 2:\n                    position, company = match\n                    position = position.strip()\n                    company = company.strip()\n                    \n                    if (len(position) > 2 and len(company) > 2 and\n                        not any(word in position.lower() for word in ['email', 'phone', 'http']) and\n                        not any(word in company.lower() for word in ['email', 'phone', 'http'])):\n                        \n                        if position not in experience['positions']:\n                            experience['positions'].append(position)\n                        if company not in experience['companies']:\n                            experience['companies'].append(company)\n        \n        return experience\n    \n    def extract_education(self, text):\n        \"\"\"Extract education information\"\"\"\n        education = {\n            'highest_degree': 'Unknown',\n            'degrees': [],\n            'institutions': []\n        }\n        \n        if not text:\n            return education\n        \n        text_lower = text.lower()\n        \n        # Degree patterns with institutions\n        degree_patterns = [\n            (r'\\b(ph\\.?d|doctorate)\\b', 'PhD'),\n            (r'\\b(m\\.?s|m\\.?a|master\\'?s?|mba)\\b', 'Masters'),\n            (r'\\b(b\\.?s|b\\.?a|bachelor\\'?s?|undergraduate)\\b', 'Bachelors'),\n            (r'\\b(associate|diploma|certificate)\\b', 'Diploma')\n        ]\n        \n        found_degrees = []\n        for pattern, degree in degree_patterns:\n            if re.search(pattern, text_lower):\n                found_degrees.append(degree)\n        \n        education['degrees'] = found_degrees\n        \n        # Determine highest degree\n        if 'PhD' in found_degrees:\n            education['highest_degree'] = 'PhD'\n        elif 'Masters' in found_degrees:\n            education['highest_degree'] = 'Masters'\n        elif 'Bachelors' in found_degrees:\n            education['highest_degree'] = 'Bachelors'\n        elif 'Diploma' in found_degrees:\n            education['highest_degree'] = 'Diploma'\n        \n        # Extract institution names (simple pattern)\n        institution_keywords = ['university', 'college', 'institute', 'school']\n        lines = text.split('\\n')\n        for line in lines:\n            line_lower = line.lower()\n            if any(keyword in line_lower for keyword in institution_keywords):\n                # Check if this line likely contains an institution name\n                if (len(line.strip()) > 5 and len(line.strip()) < 100 and\n                    not any(word in line_lower for word in ['experience', 'skills', 'projects'])):\n                    education['institutions'].append(line.strip())\n        \n        return education\n\n# Test the parser\nif __name__ == \"__main__\":\n    print(\"üß™ Testing Resume Parser...\")\n    \n    parser = ResumeParser()\n    \n    # Test with sample resume text\n    sample_resume = \"\"\"\n    JOHN DOE\n    Senior Software Engineer\n    Email: john.doe@email.com\n    Phone: (555) 123-4567\n    Location: San Francisco, CA\n    \n    EXPERIENCE:\n    Senior Python Developer - Tech Solutions Inc. (2020-2023)\n    ‚Ä¢ Developed web applications using Python and Django\n    ‚Ä¢ Led a team of 5 developers\n    \n    Python Developer - Startup Co. (2018-2020)\n    ‚Ä¢ Built REST APIs and microservices\n    \n    EDUCATION:\n    Bachelor of Science in Computer Science - State University (2014-2018)\n    \n    SKILLS:\n    Programming: Python, Java, JavaScript\n    Web: HTML, CSS, React, Django\n    Database: SQL, MongoDB\n    Tools: Git, Docker, AWS\n    \"\"\"\n    \n    personal_info = parser.parse_personal_info(sample_resume)\n    skills = parser.extract_skills(sample_resume)\n    experience = parser.extract_experience(sample_resume)\n    education = parser.extract_education(sample_resume)\n    \n    print(\"‚úÖ Parser tested successfully!\")\n    print(f\"Name: {personal_info['name']}\")\n    print(f\"Email: {personal_info['email']}\")\n    print(f\"Phone: {personal_info['phone']}\")\n    print(f\"Skills Categories: {len(skills)}\")\n    print(f\"Experience: {experience['total_years']} years\")\n    print(f\"Highest Degree: {education['highest_degree']}\")","size_bytes":12328},"utils/__init__.py":{"content":"","size_bytes":0},"utils/feature_extractor.py":{"content":"import re\nimport numpy as np\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom collections import Counter\n\nclass FeatureExtractor:\n    def __init__(self):\n        self.tfidf_vectorizer = TfidfVectorizer(\n            max_features=1000, \n            stop_words='english',\n            ngram_range=(1, 2)  # Include bigrams\n        )\n        self.count_vectorizer = CountVectorizer(\n            max_features=500,\n            stop_words='english'\n        )\n    \n    def extract_text_features(self, text):\n        \"\"\"Extract comprehensive text-based features\"\"\"\n        features = {}\n        \n        if not text:\n            return self._get_empty_features()\n        \n        try:\n            # Basic text statistics\n            features['char_count'] = len(text)\n            features['word_count'] = len(text.split())\n            features['sentence_count'] = len(re.split(r'[.!?]+', text))\n            \n            # Word and character statistics\n            words = text.split()\n            if words:\n                features['avg_word_length'] = sum(len(word) for word in words) / len(words)\n                features['max_word_length'] = max(len(word) for word in words)\n                features['unique_word_ratio'] = len(set(words)) / len(words)\n            else:\n                features['avg_word_length'] = 0\n                features['max_word_length'] = 0\n                features['unique_word_ratio'] = 0\n            \n            # Extract numeric features\n            numbers = re.findall(r'\\b\\d+\\b', text)\n            features['number_count'] = len(numbers)\n            if numbers:\n                features['avg_number'] = sum(map(int, numbers)) / len(numbers)\n            else:\n                features['avg_number'] = 0\n            \n            # Contact information features\n            emails = re.findall(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b', text)\n            features['email_count'] = len(emails)\n            \n            phone_patterns = [\n                r'(\\+?\\d{1,3}[-.\\s]?)?\\(?\\d{3}\\)?[-.\\s]?\\d{3}[-.\\s]?\\d{4}',\n                r'\\+?[\\d\\s-]{10,}'\n            ]\n            phone_count = 0\n            for pattern in phone_patterns:\n                phone_count += len(re.findall(pattern, text))\n            features['phone_count'] = phone_count\n            \n            # URL features\n            urls = re.findall(r'http\\S+|www\\S+|https\\S+', text)\n            features['url_count'] = len(urls)\n            \n            # Section detection features\n            section_keywords = {\n                'experience': ['experience', 'work', 'employment', 'career'],\n                'education': ['education', 'academic', 'degree', 'university'],\n                'skills': ['skills', 'technical', 'programming', 'languages'],\n                'projects': ['projects', 'portfolio', 'work samples'],\n                'certifications': ['certifications', 'certificate', 'licenses']\n            }\n            \n            text_lower = text.lower()\n            for section, keywords in section_keywords.items():\n                features[f'{section}_section'] = any(keyword in text_lower for keyword in keywords)\n            \n            # Keyword density features\n            technical_keywords = ['python', 'java', 'javascript', 'sql', 'aws', 'docker', 'machine learning']\n            business_keywords = ['management', 'leadership', 'strategy', 'business', 'marketing']\n            \n            features['technical_keyword_density'] = sum(text_lower.count(keyword) for keyword in technical_keywords) / max(1, features['word_count'])\n            features['business_keyword_density'] = sum(text_lower.count(keyword) for keyword in business_keywords) / max(1, features['word_count'])\n            \n            return features\n            \n        except Exception as e:\n            print(f\"Error extracting text features: {e}\")\n            return self._get_empty_features()\n    \n    def extract_skill_features(self, skills_dict):\n        \"\"\"Extract features from skills dictionary\"\"\"\n        features = {}\n        \n        try:\n            if not skills_dict:\n                return self._get_empty_skill_features()\n            \n            total_skills = sum(len(skills) for skills in skills_dict.values())\n            features['total_skills'] = total_skills\n            \n            # Count skills by category\n            skill_categories = {\n                'technical': ['Programming', 'Web Development', 'Database', 'Cloud & DevOps', 'AI/ML', 'Data Science', 'Tools & Platforms'],\n                'soft': ['Soft Skills'],\n                'other': []  # Any other categories\n            }\n            \n            technical_skills = 0\n            soft_skills = 0\n            other_skills = 0\n            \n            for category, skills in skills_dict.items():\n                category_skill_count = len(skills)\n                features[f'{category.lower().replace(\" & \", \"_\").replace(\" \", \"_\")}_count'] = category_skill_count\n                \n                if category in skill_categories['technical']:\n                    technical_skills += category_skill_count\n                elif category in skill_categories['soft']:\n                    soft_skills += category_skill_count\n                else:\n                    other_skills += category_skill_count\n            \n            features['technical_skills_count'] = technical_skills\n            features['soft_skills_count'] = soft_skills\n            features['other_skills_count'] = other_skills\n            \n            # Ratios\n            if total_skills > 0:\n                features['technical_ratio'] = technical_skills / total_skills\n                features['soft_ratio'] = soft_skills / total_skills\n                features['skill_diversity'] = len(skills_dict) / total_skills\n            else:\n                features['technical_ratio'] = 0\n                features['soft_ratio'] = 0\n                features['skill_diversity'] = 0\n            \n            # Skill depth (average skills per category)\n            features['avg_skills_per_category'] = total_skills / max(1, len(skills_dict))\n            \n            return features\n            \n        except Exception as e:\n            print(f\"Error extracting skill features: {e}\")\n            return self._get_empty_skill_features()\n    \n    def extract_experience_features(self, experience_data):\n        \"\"\"Extract features from experience data\"\"\"\n        features = {}\n        \n        try:\n            features['experience_years'] = experience_data.get('total_years', 0)\n            features['position_count'] = len(experience_data.get('positions', []))\n            features['company_count'] = len(experience_data.get('companies', []))\n            \n            # Experience level categorization\n            exp_years = features['experience_years']\n            if exp_years >= 10:\n                features['experience_level'] = 'senior'\n            elif exp_years >= 5:\n                features['experience_level'] = 'mid'\n            elif exp_years >= 2:\n                features['experience_level'] = 'junior'\n            else:\n                features['experience_level'] = 'entry'\n            \n            # Career progression indicator\n            positions = experience_data.get('positions', [])\n            senior_keywords = ['senior', 'lead', 'principal', 'manager', 'director', 'head']\n            junior_keywords = ['junior', 'associate', 'assistant', 'intern']\n            \n            senior_positions = sum(1 for pos in positions if any(keyword in pos.lower() for keyword in senior_keywords))\n            junior_positions = sum(1 for pos in positions if any(keyword in pos.lower() for keyword in junior_keywords))\n            \n            features['senior_position_ratio'] = senior_positions / max(1, len(positions))\n            features['junior_position_ratio'] = junior_positions / max(1, len(positions))\n            \n            return features\n            \n        except Exception as e:\n            print(f\"Error extracting experience features: {e}\")\n            return {'experience_years': 0, 'position_count': 0, 'company_count': 0, 'experience_level': 'unknown'}\n    \n    def extract_education_features(self, education_data):\n        \"\"\"Extract features from education data\"\"\"\n        features = {}\n        \n        try:\n            highest_degree = education_data.get('highest_degree', 'Unknown')\n            degree_scores = {\n                'PhD': 4,\n                'Masters': 3,\n                'Bachelors': 2,\n                'Diploma': 1,\n                'Unknown': 0\n            }\n            \n            features['education_score'] = degree_scores.get(highest_degree, 0)\n            features['degree_count'] = len(education_data.get('degrees', []))\n            features['institution_count'] = len(education_data.get('institutions', []))\n            features['has_higher_education'] = features['education_score'] >= 2\n            \n            return features\n            \n        except Exception as e:\n            print(f\"Error extracting education features: {e}\")\n            return {'education_score': 0, 'degree_count': 0, 'institution_count': 0, 'has_higher_education': False}\n    \n    def get_tfidf_features(self, texts):\n        \"\"\"Get TF-IDF features for multiple texts\"\"\"\n        try:\n            if not texts or len(texts) == 0:\n                return None\n            \n            # Ensure all texts are strings\n            texts = [str(text) for text in texts if text]\n            \n            if len(texts) == 0:\n                return None\n            \n            return self.tfidf_vectorizer.fit_transform(texts)\n            \n        except Exception as e:\n            print(f\"Error generating TF-IDF features: {e}\")\n            return None\n    \n    def get_count_features(self, texts):\n        \"\"\"Get count vectorizer features\"\"\"\n        try:\n            if not texts or len(texts) == 0:\n                return None\n            \n            texts = [str(text) for text in texts if text]\n            \n            if len(texts) == 0:\n                return None\n            \n            return self.count_vectorizer.fit_transform(texts)\n            \n        except Exception as e:\n            print(f\"Error generating count features: {e}\")\n            return None\n    \n    def _get_empty_features(self):\n        \"\"\"Return empty feature set\"\"\"\n        return {\n            'char_count': 0, 'word_count': 0, 'sentence_count': 0,\n            'avg_word_length': 0, 'max_word_length': 0, 'unique_word_ratio': 0,\n            'number_count': 0, 'avg_number': 0, 'email_count': 0,\n            'phone_count': 0, 'url_count': 0,\n            'technical_keyword_density': 0, 'business_keyword_density': 0\n        }\n    \n    def _get_empty_skill_features(self):\n        \"\"\"Return empty skill feature set\"\"\"\n        return {\n            'total_skills': 0, 'technical_skills_count': 0,\n            'soft_skills_count': 0, 'other_skills_count': 0,\n            'technical_ratio': 0, 'soft_ratio': 0, 'skill_diversity': 0,\n            'avg_skills_per_category': 0\n        }\n\n# Test the feature extractor\nif __name__ == \"__main__\":\n    print(\"üß™ Testing Feature Extractor...\")\n    \n    extractor = FeatureExtractor()\n    \n    # Test with sample data\n    sample_text = \"Python developer with 5 years experience. Skills: Python, Django, React.\"\n    sample_skills = {\n        'Programming': ['python', 'javascript'],\n        'Web Development': ['django', 'react']\n    }\n    sample_experience = {'total_years': 5, 'positions': ['Developer'], 'companies': ['Tech Co']}\n    sample_education = {'highest_degree': 'Bachelors', 'degrees': ['Bachelors'], 'institutions': ['University']}\n    \n    text_features = extractor.extract_text_features(sample_text)\n    skill_features = extractor.extract_skill_features(sample_skills)\n    exp_features = extractor.extract_experience_features(sample_experience)\n    edu_features = extractor.extract_education_features(sample_education)\n    \n    print(\"‚úÖ Feature Extractor tested successfully!\")\n    print(f\"Text Features: {len(text_features)}\")\n    print(f\"Skill Features: {len(skill_features)}\")\n    print(f\"Experience Features: {len(exp_features)}\")\n    print(f\"Education Features: {len(edu_features)}\")","size_bytes":12249},"utils/preprocessor.py":{"content":"import re\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nimport string\n\nclass TextPreprocessor:\n    def __init__(self):\n        # Download required NLTK data if not present\n        try:\n            nltk.data.find('tokenizers/punkt')\n        except LookupError:\n            nltk.download('punkt', quiet=True)\n        \n        try:\n            nltk.data.find('corpora/stopwords')\n        except LookupError:\n            nltk.download('stopwords', quiet=True)\n        \n        self.stop_words = set(stopwords.words('english'))\n        self.custom_stop_words = {\n            'resume', 'cv', 'curriculum', 'vitae', 'page', 'email', 'phone', \n            'mobile', 'tel', 'address', 'linkedin', 'github', 'portfolio'\n        }\n        \n        # Combine standard and custom stop words\n        self.all_stop_words = self.stop_words.union(self.custom_stop_words)\n    \n    def clean_text(self, text):\n        \"\"\"Clean and normalize text\"\"\"\n        if not text or not isinstance(text, str):\n            return \"\"\n        \n        # Convert to lowercase\n        text = text.lower()\n        \n        # Remove URLs\n        text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n        \n        # Remove email addresses\n        text = re.sub(r'\\S+@\\S+', '', text)\n        \n        # Remove phone numbers\n        text = re.sub(r'[\\+\\(]?[1-9][0-9 .\\-\\(\\)]{8,}[0-9]', '', text)\n        \n        # Remove special characters but keep basic punctuation for sentence detection\n        text = re.sub(r'[^\\w\\s\\.\\,\\!\\\\?]', '', text)\n        \n        # Remove extra whitespace\n        text = re.sub(r'\\s+', ' ', text).strip()\n        \n        return text\n    \n    def tokenize_text(self, text):\n        \"\"\"Tokenize text into words\"\"\"\n        try:\n            return word_tokenize(text)\n        except Exception as e:\n            print(f\"Tokenization error: {e}\")\n            return text.split()  # Fallback to simple split\n    \n    def remove_stopwords(self, tokens):\n        \"\"\"Remove stopwords from token list\"\"\"\n        return [token for token in tokens if token not in self.all_stop_words]\n    \n    def preprocess(self, text):\n        \"\"\"Complete preprocessing pipeline\"\"\"\n        try:\n            # Clean text\n            cleaned_text = self.clean_text(text)\n            \n            # Tokenize\n            tokens = self.tokenize_text(cleaned_text)\n            \n            # Remove stopwords\n            filtered_tokens = self.remove_stopwords(tokens)\n            \n            return ' '.join(filtered_tokens)\n            \n        except Exception as e:\n            print(f\"Preprocessing error: {e}\")\n            return text  # Return original text if preprocessing fails\n    \n    def extract_sentences(self, text):\n        \"\"\"Extract sentences from text\"\"\"\n        try:\n            # Simple sentence splitting\n            sentences = re.split(r'[.!?]+', text)\n            return [sentence.strip() for sentence in sentences if sentence.strip()]\n        except Exception as e:\n            print(f\"Sentence extraction error: {e}\")\n            return [text]\n    \n    def extract_paragraphs(self, text):\n        \"\"\"Extract paragraphs from text\"\"\"\n        try:\n            paragraphs = text.split('\\n\\n')\n            return [para.strip() for para in paragraphs if para.strip()]\n        except Exception as e:\n            print(f\"Paragraph extraction error: {e}\")\n            return [text]\n    \n    def calculate_readability_score(self, text):\n        \"\"\"Calculate basic readability score\"\"\"\n        try:\n            sentences = self.extract_sentences(text)\n            words = self.tokenize_text(text)\n            \n            if len(sentences) == 0 or len(words) == 0:\n                return 0\n            \n            # Average sentence length\n            avg_sentence_length = len(words) / len(sentences)\n            \n            # Simple readability score (lower = more complex)\n            readability_score = avg_sentence_length\n            \n            return min(readability_score, 50)  # Cap at 50\n            \n        except Exception as e:\n            print(f\"Readability calculation error: {e}\")\n            return 0\n\n# Test the preprocessor\nif __name__ == \"__main__\":\n    print(\"üß™ Testing Text Preprocessor...\")\n    \n    preprocessor = TextPreprocessor()\n    \n    # Test with sample text\n    sample_text = \"\"\"\n    John Doe is a Senior Software Engineer with 5 years of experience.\n    He specializes in Python development and machine learning.\n    Email: john.doe@email.com\n    Phone: (555) 123-4567\n    \"\"\"\n    \n    processed_text = preprocessor.preprocess(sample_text)\n    sentences = preprocessor.extract_sentences(sample_text)\n    readability = preprocessor.calculate_readability_score(sample_text)\n    \n    print(\"‚úÖ Preprocessor tested successfully!\")\n    print(f\"Original: {sample_text[:100]}...\")\n    print(f\"Processed: {processed_text[:100]}...\")\n    print(f\"Sentences: {len(sentences)}\")\n    print(f\"Readability Score: {readability:.2f}\")","size_bytes":4998},"models/ranker.py":{"content":"import numpy as np\nfrom datetime import datetime\n\nclass ResumeRanker:\n    def __init__(self):\n        self.department_weights = {\n            'IT': {'technical_skills': 0.4, 'experience': 0.3, 'education': 0.2, 'certifications': 0.1},\n            'HR': {'experience': 0.4, 'soft_skills': 0.3, 'education': 0.2, 'certifications': 0.1},\n            'Finance': {'experience': 0.5, 'education': 0.3, 'certifications': 0.2},\n            'Marketing': {'experience': 0.4, 'soft_skills': 0.3, 'education': 0.2, 'portfolio': 0.1},\n            'Engineering': {'technical_skills': 0.5, 'experience': 0.3, 'education': 0.2},\n            'Operations': {'experience': 0.5, 'soft_skills': 0.3, 'education': 0.2},\n            'Sales': {'experience': 0.4, 'soft_skills': 0.4, 'education': 0.2},\n            'General': {'experience': 0.4, 'skills': 0.4, 'education': 0.2}\n        }\n    \n    def calculate_department_score(self, candidate, department):\n        \"\"\"Calculate score for a candidate in a specific department\"\"\"\n        if department not in self.department_weights:\n            department = 'General'\n        \n        weights = self.department_weights[department]\n        score = 0\n        \n        # Experience component\n        experience_years = candidate.get('experience_years', 0)\n        score += min(experience_years / 10.0, 1.0) * weights.get('experience', 0.3) * 100\n        \n        # Skills component\n        skills = candidate.get('skills', {})\n        total_skills = sum(len(skills[cat]) for cat in skills)\n        \n        if 'technical_skills' in weights:\n            tech_skills = len(skills.get('Programming', [])) + len(skills.get('AI/ML', [])) + len(skills.get('Web Development', []))\n            score += min(tech_skills / 10.0, 1.0) * weights['technical_skills'] * 100\n        elif 'soft_skills' in weights:\n            soft_skills = len(skills.get('Soft Skills', []))\n            score += min(soft_skills / 5.0, 1.0) * weights['soft_skills'] * 100\n        else:\n            score += min(total_skills / 15.0, 1.0) * weights.get('skills', 0.3) * 100\n        \n        # Education component\n        education_level = candidate.get('education_level', 'Unknown')\n        education_score = 0\n        if education_level == 'PhD':\n            education_score = 1.0\n        elif education_level == 'Masters':\n            education_score = 0.8\n        elif education_level == 'Bachelors':\n            education_score = 0.6\n        elif education_level == 'Diploma':\n            education_score = 0.4\n        \n        score += education_score * weights.get('education', 0.2) * 100\n        \n        return min(score, 100)\n    \n    def rank_candidates_by_department(self, candidates, department, top_n=5):\n        \"\"\"Rank candidates within a specific department\"\"\"\n        dept_candidates = [c for c in candidates if c.get('department') == department]\n        \n        # Calculate department-specific scores\n        for candidate in dept_candidates:\n            candidate['department_score'] = self.calculate_department_score(candidate, department)\n        \n        # Sort by department score (primary) and overall ranking score (secondary)\n        ranked_candidates = sorted(\n            dept_candidates, \n            key=lambda x: (x.get('department_score', 0), x.get('ranking_score', 0)), \n            reverse=True\n        )\n        \n        return ranked_candidates[:top_n]\n    \n    def get_top_candidates_all_departments(self, candidates, top_n=5):\n        \"\"\"Get top candidates from all departments\"\"\"\n        departments = set(candidate.get('department', 'General') for candidate in candidates)\n        top_candidates = {}\n        \n        for department in departments:\n            top_candidates[department] = self.rank_candidates_by_department(candidates, department, top_n)\n        \n        return top_candidates\n    \n    def get_overall_ranking(self, candidates, top_n=10):\n        \"\"\"Get overall ranking across all departments\"\"\"\n        # Calculate overall scores considering department fit\n        for candidate in candidates:\n            department = candidate.get('department', 'General')\n            department_score = self.calculate_department_score(candidate, department)\n            ranking_score = candidate.get('ranking_score', 0)\n            \n            # Combined score: 60% ranking score + 40% department fit\n            candidate['overall_score'] = (ranking_score * 0.6) + (department_score * 0.4)\n        \n        # Sort by overall score\n        ranked_candidates = sorted(candidates, key=lambda x: x.get('overall_score', 0), reverse=True)\n        \n        return ranked_candidates[:top_n]\n\n# Test the ranker\nif __name__ == \"__main__\":\n    print(\"üß™ Testing Resume Ranker...\")\n    \n    ranker = ResumeRanker()\n    \n    # Test with sample candidates\n    test_candidates = [\n        {\n            'candidate_name': 'John Doe',\n            'department': 'IT',\n            'ranking_score': 85,\n            'experience_years': 5,\n            'education_level': 'Bachelors',\n            'skills': {\n                'Programming': ['python', 'java'],\n                'Web Development': ['html', 'css', 'javascript'],\n                'Database': ['sql']\n            }\n        },\n        {\n            'candidate_name': 'Jane Smith',\n            'department': 'HR',\n            'ranking_score': 78,\n            'experience_years': 3,\n            'education_level': 'Masters',\n            'skills': {\n                'Soft Skills': ['communication', 'leadership', 'teamwork']\n            }\n        }\n    ]\n    \n    top_by_dept = ranker.get_top_candidates_all_departments(test_candidates)\n    overall_ranking = ranker.get_overall_ranking(test_candidates)\n    \n    print(\"‚úÖ Ranker tested successfully!\")\n    print(f\"Departments: {list(top_by_dept.keys())}\")\n    print(f\"Overall top: {len(overall_ranking)} candidates\")","size_bytes":5840},"models/classifier.py":{"content":"import pandas as pd\nimport numpy as np\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.ensemble import RandomForestClassifier\nimport joblib\nimport os\nimport re\n\nclass ResumeClassifier:\n    def __init__(self):\n        self.departments = ['IT', 'HR', 'Finance', 'Marketing', 'Engineering', 'Operations', 'Sales']\n        self.vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')\n        self.classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n        self.is_trained = False\n        self.load_or_train_model()\n    \n    def load_or_train_model(self):\n        \"\"\"Load existing model or train new one\"\"\"\n        try:\n            if os.path.exists('data/trained_models/vectorizer.pkl') and os.path.exists('data/trained_models/classifier.pkl'):\n                self.vectorizer = joblib.load('data/trained_models/vectorizer.pkl')\n                self.classifier = joblib.load('data/trained_models/classifier.pkl')\n                self.is_trained = True\n                print(\"‚úÖ Pre-trained models loaded successfully!\")\n            else:\n                self.train_model()\n        except Exception as e:\n            print(f\"‚ö†Ô∏è Error loading models: {e}. Training new models...\")\n            self.train_model()\n    \n    def train_model(self):\n        \"\"\"Train the classification model with enhanced training data\"\"\"\n        try:\n            # Enhanced training data with more examples\n            training_data = {\n                'texts': [\n                    # IT examples\n                    \"python java programming software development web database sql cloud aws docker kubernetes backend frontend\",\n                    \"javascript react node.js web development full stack mobile app programming api rest\",\n                    \"data science machine learning python sql analysis visualization pandas numpy\",\n                    \"devops aws azure cloud infrastructure docker kubernetes ci cd jenkins\",\n                    \n                    # HR examples\n                    \"recruitment hiring talent acquisition HR management interviewing onboarding employee relations\",\n                    \"human resources payroll benefits compensation training development performance management\",\n                    \"recruiter sourcing screening candidates HR policies compliance diversity inclusion\",\n                    \n                    # Finance examples\n                    \"accounting finance budgeting financial analysis audit tax investment banking\",\n                    \"financial planning analysis fpa forecasting budgeting reporting excel\",\n                    \"accountant bookkeeping gaap financial statements audit tax preparation\",\n                    \n                    # Marketing examples\n                    \"marketing sales digital social media SEO content strategy advertising branding\",\n                    \"digital marketing google analytics seo sem social media content creation\",\n                    \"brand management product marketing market research campaign management\",\n                    \n                    # Engineering examples\n                    \"engineering mechanical electrical civil design construction manufacturing\",\n                    \"mechanical engineer design cad solidworks manufacturing production\",\n                    \"civil engineer construction project management structural design\",\n                    \n                    # Operations examples\n                    \"operations supply chain logistics management production quality control\",\n                    \"supply chain logistics inventory management procurement operations\",\n                    \"project management operations process improvement lean manufacturing\",\n                    \n                    # Sales examples\n                    \"sales business development client relationship negotiation deal closing\",\n                    \"account executive sales representative business development b2b sales\",\n                    \"sales manager team leadership revenue growth customer acquisition\"\n                ],\n                'labels': [0, 0, 0, 0, 1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6]\n            }\n            \n            X = self.vectorizer.fit_transform(training_data['texts'])\n            self.classifier.fit(X, training_data['labels'])\n            self.is_trained = True\n            \n            # Ensure directory exists\n            os.makedirs('data/trained_models', exist_ok=True)\n            \n            # Save models\n            joblib.dump(self.vectorizer, 'data/trained_models/vectorizer.pkl')\n            joblib.dump(self.classifier, 'data/trained_models/classifier.pkl')\n            \n            print(\"‚úÖ Model trained and saved successfully!\")\n            \n        except Exception as e:\n            print(f\"‚ùå Error training model: {e}\")\n            self.is_trained = False\n    \n    def classify_resume(self, text, skills):\n        \"\"\"Classify resume into department and status with enhanced logic\"\"\"\n        try:\n            if not self.is_trained:\n                print(\"‚ö†Ô∏è Model not trained, using fallback classification\")\n                return self.fallback_classification(skills, text)\n            \n            # Create feature text from skills and resume content\n            skill_text = \" \".join([skill for category in skills.values() for skill in category])\n            combined_text = text + \" \" + skill_text\n            \n            # Transform and predict\n            X = self.vectorizer.transform([combined_text])\n            dept_idx = self.classifier.predict(X)[0]\n            department = self.departments[dept_idx] if dept_idx < len(self.departments) else 'General'\n            \n            # Enhanced acceptance logic\n            status = self.determine_acceptance_status(skills, text)\n            \n            # Calculate comprehensive ranking score\n            ranking_score = self.calculate_ranking_score(skills, text)\n            \n            return status, department, ranking_score\n            \n        except Exception as e:\n            print(f\"‚ùå Classification error: {e}\")\n            return self.fallback_classification(skills, text)\n    \n    def determine_acceptance_status(self, skills, text):\n        \"\"\"Enhanced acceptance criteria\"\"\"\n        tech_skills = len(skills.get('Programming', [])) + len(skills.get('AI/ML', [])) + len(skills.get('Web Development', []))\n        total_skills = sum(len(skills[cat]) for cat in skills)\n        \n        # Check for experience indicators\n        year_pattern = r'\\b(19|20)\\d{2}\\b'\n        years = [int(year) for year in re.findall(year_pattern, text)]\n        has_experience = len(years) >= 2\n        \n        # Check for education indicators\n        has_education = any(degree in text.lower() for degree in ['bachelor', 'master', 'mba', 'ph.d', 'doctorate', 'degree'])\n        \n        # Enhanced acceptance rules\n        if total_skills >= 4:  # Reduced threshold for better acceptance\n            return \"Accepted\"\n        elif tech_skills >= 2 and has_experience:\n            return \"Accepted\"\n        elif has_education and total_skills >= 2:\n            return \"Accepted\"\n        elif total_skills >= 3:  # More lenient for diverse skills\n            return \"Accepted\"\n        else:\n            return \"Rejected\"\n    \n    def calculate_ranking_score(self, skills, text):\n        \"\"\"Calculate comprehensive ranking score (0-100)\"\"\"\n        score = 0\n        \n        # Skills component (40 points max)\n        total_skills = sum(len(skills[cat]) for cat in skills)\n        score += min(total_skills * 4, 40)  # 4 points per skill, max 40\n        \n        # Technical skills bonus (20 points max)\n        tech_skills = len(skills.get('Programming', [])) + len(skills.get('AI/ML', [])) + len(skills.get('Web Development', []))\n        score += min(tech_skills * 5, 20)  # 5 points per tech skill, max 20\n        \n        # Experience component (20 points max)\n        year_pattern = r'\\b(19|20)\\d{2}\\b'\n        years = [int(year) for year in re.findall(year_pattern, text)]\n        if years:\n            exp_years = max(years) - min(years)\n            score += min(exp_years * 4, 20)  # 4 points per year, max 20\n        \n        # Education component (20 points max)\n        education_bonus = 0\n        text_lower = text.lower()\n        \n        if 'ph.d' in text_lower or 'doctorate' in text_lower:\n            education_bonus = 20\n        elif 'master' in text_lower or 'mba' in text_lower:\n            education_bonus = 15\n        elif 'bachelor' in text_lower or 'b.s.' in text_lower or 'b.a.' in text_lower:\n            education_bonus = 10\n        elif 'diploma' in text_lower or 'associate' in text_lower:\n            education_bonus = 5\n        \n        score += education_bonus\n        \n        return min(score, 100)\n    \n    def detect_fraud(self, text, skills, experience):\n        \"\"\"Enhanced fraud detection with multiple checks\"\"\"\n        findings = []\n        score = 0\n        \n        # AI-generated content detection (25 points)\n        ai_patterns = [\n            r\"\\b(as an AI|language model|I cannot|I am unable to)\\b\",\n            r\"\\b(based on my training|according to my knowledge)\\b\",\n            r\"\\b(I don't have|I do not have)\\b\",\n            r\"\\b(as a large language model)\\b\",\n            r\"\\b(I am designed to|I am programmed to)\\b\"\n        ]\n        \n        text_lower = text.lower()\n        for pattern in ai_patterns:\n            if re.search(pattern, text_lower, re.IGNORECASE):\n                score += 25\n                findings.append(\"ü§ñ AI-generated content patterns detected\")\n                break\n        \n        # Skill exaggeration check (20 points)\n        total_skills = sum(len(skills[cat]) for cat in skills)\n        if total_skills > 25:\n            score += 25\n            findings.append(\"üìö Unusually high number of skills listed (>25)\")\n        elif total_skills > 15:\n            score += 15\n            findings.append(\"üìñ High number of skills listed (>15)\")\n        \n        # Experience-skills mismatch (20 points)\n        exp_years = experience.get('total_years', 0)\n        if exp_years < 2 and total_skills > 12:\n            score += 20\n            findings.append(\"‚öñÔ∏è Skills-to-experience ratio suspicious\")\n        \n        # Date consistency check (30 points)\n        year_pattern = r'\\b(19|20)\\d{2}\\b'\n        years = [int(year) for year in re.findall(year_pattern, text)]\n        if len(years) >= 2:\n            sorted_years = sorted(years)\n            if years != sorted_years:\n                score += 30\n                findings.append(\"üìÖ Date inconsistencies detected - timeline issues\")\n        \n        # Education level verification (15 points)\n        education_keywords = {\n            'high_school': ['high school', 'diploma'],\n            'bachelors': ['bachelor', 'b.s.', 'b.a.', 'undergraduate'],\n            'masters': ['master', 'm.s.', 'm.a.', 'mba', 'graduate'],\n            'phd': ['ph.d', 'doctorate', 'phd']\n        }\n        \n        education_levels_found = []\n        for level, keywords in education_keywords.items():\n            if any(keyword in text_lower for keyword in keywords):\n                education_levels_found.append(level)\n        \n        if len(education_levels_found) > 2:\n            score += 15\n            findings.append(\"üéì Multiple education levels claimed\")\n        \n        # Contact information check (10 points)\n        email_pattern = r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'\n        phone_pattern = r'(\\+?\\d{1,3}[-.\\s]?)?\\(?\\d{3}\\)?[-.\\s]?\\d{3}[-.\\s]?\\d{4}'\n        \n        emails = re.findall(email_pattern, text)\n        phones = re.findall(phone_pattern, text)\n        \n        if len(emails) == 0 and len(phones) == 0:\n            score += 10\n            findings.append(\"üìû Missing contact information\")\n        \n        # Text quality check (10 points)\n        if len(text.strip()) < 100:\n            score += 10\n            findings.append(\"üìù Very short resume content\")\n        \n        return min(score, 100), findings\n    \n    def fallback_classification(self, skills, text):\n        \"\"\"Fallback classification when ML model fails\"\"\"\n        tech_skills = len(skills.get('Programming', [])) + len(skills.get('AI/ML', [])) + len(skills.get('Web Development', []))\n        total_skills = sum(len(skills[cat]) for cat in skills)\n        \n        # Simple rule-based department assignment\n        if tech_skills >= 2:\n            department = \"IT\"\n        elif len(skills.get('Soft Skills', [])) >= 3:\n            department = \"HR\"\n        elif any(finance in text.lower() for finance in ['finance', 'accounting', 'banking']):\n            department = \"Finance\"\n        elif any(marketing in text.lower() for marketing in ['marketing', 'sales', 'advertising']):\n            department = \"Marketing\"\n        else:\n            department = \"General\"\n        \n        # Simple acceptance\n        status = \"Accepted\" if total_skills >= 3 else \"Rejected\"\n        \n        # Basic ranking\n        ranking_score = min(total_skills * 15, 100)\n        \n        return status, department, ranking_score\n\n# Test the classifier\nif __name__ == \"__main__\":\n    print(\"üß™ Testing Resume Classifier...\")\n    \n    classifier = ResumeClassifier()\n    \n    # Test with sample data\n    test_text = \"Python developer with 5 years experience in web development and machine learning. Bachelor's degree in Computer Science.\"\n    test_skills = {\n        'Programming': ['python', 'java'],\n        'Web Development': ['html', 'css', 'javascript'],\n        'Database': ['sql', 'mongodb'],\n        'AI/ML': ['machine learning']\n    }\n    test_experience = {'total_years': 5}\n    \n    status, department, score = classifier.classify_resume(test_text, test_skills)\n    fraud_score, findings = classifier.detect_fraud(test_text, test_skills, test_experience)\n    \n    print(f\"‚úÖ Classification: {status} | Department: {department} | Score: {score}\")\n    print(f\"‚úÖ Fraud Detection: {fraud_score}%\")\n    print(\"Findings:\", findings)","size_bytes":14072},"test_app.py":{"content":"#!/usr/bin/env python3\n\"\"\"\nTest script for Smart Resume Analyzer\nRun this to check if all components are working correctly\n\"\"\"\n\nimport sys\nimport os\nimport sqlite3\nimport tempfile\nimport shutil\nfrom datetime import datetime\n\n# Add current directory to Python path\nsys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))\n\ndef print_status(message, status=\"INFO\"):\n    \"\"\"Print colored status messages\"\"\"\n    colors = {\n        \"INFO\": \"\\033[94m\",    # Blue\n        \"SUCCESS\": \"\\033[92m\", # Green\n        \"WARNING\": \"\\033[93m\", # Yellow\n        \"ERROR\": \"\\033[91m\",   # Red\n        \"END\": \"\\033[0m\"       # Reset\n    }\n    print(f\"{colors.get(status, '')}[{status}] {message}{colors['END']}\")\n\ndef test_imports():\n    \"\"\"Test if all required modules can be imported\"\"\"\n    print_status(\"Testing module imports...\", \"INFO\")\n    \n    modules_to_test = [\n        (\"Flask\", \"flask\"),\n        (\"SQLAlchemy\", \"flask_sqlalchemy\"),\n        (\"PyPDF2\", \"PyPDF2\"),\n        (\"python-docx\", \"docx\"),\n        (\"scikit-learn\", \"sklearn\"),\n        (\"numpy\", \"numpy\"),\n        (\"pandas\", \"pandas\"),\n        (\"nltk\", \"nltk\"),\n        (\"joblib\", \"joblib\")\n    ]\n    \n    all_imports_ok = True\n    for module_name, import_name in modules_to_test:\n        try:\n            if import_name == \"flask_sqlalchemy\":\n                __import__(\"flask_sqlalchemy\")\n            else:\n                __import__(import_name)\n            print_status(f\"‚úÖ {module_name}\", \"SUCCESS\")\n        except ImportError as e:\n            print_status(f\"‚ùå {module_name} - {e}\", \"ERROR\")\n            all_imports_ok = False\n    \n    return all_imports_ok\n\ndef test_custom_modules():\n    \"\"\"Test if our custom modules can be imported\"\"\"\n    print_status(\"Testing custom modules...\", \"INFO\")\n    \n    custom_modules = [\n        (\"ResumeParser\", \"utils.parser\"),\n        (\"TextPreprocessor\", \"utils.preprocessor\"),\n        (\"FeatureExtractor\", \"utils.feature_extractor\"),\n        (\"ResumeClassifier\", \"models.classifier\"),\n        (\"ResumeRanker\", \"models.ranker\")\n    ]\n    \n    all_custom_ok = True\n    for class_name, module_path in custom_modules:\n        try:\n            module = __import__(module_path, fromlist=[class_name])\n            getattr(module, class_name)\n            print_status(f\"‚úÖ {class_name}\", \"SUCCESS\")\n        except ImportError as e:\n            print_status(f\"‚ùå {class_name} - {e}\", \"ERROR\")\n            all_custom_ok = False\n        except AttributeError as e:\n            print_status(f\"‚ùå {class_name} - Class not found\", \"ERROR\")\n            all_custom_ok = False\n    \n    return all_custom_ok\n\ndef test_database():\n    \"\"\"Test database connection and operations\"\"\"\n    print_status(\"Testing database...\", \"INFO\")\n    \n    try:\n        from app import app, db, ResumeAnalysis\n        \n        with app.app_context():\n            # Create all tables\n            db.create_all()\n            print_status(\"‚úÖ Database tables created\", \"SUCCESS\")\n            \n            # Test basic CRUD operations\n            test_analysis = ResumeAnalysis(\n                filename=\"test_file.pdf\",\n                candidate_name=\"Test Candidate\",\n                candidate_email=\"test@example.com\",\n                classification_status=\"Accepted\",\n                department=\"IT\",\n                ranking_score=85.5\n            )\n            \n            db.session.add(test_analysis)\n            db.session.commit()\n            print_status(\"‚úÖ Database write operation\", \"SUCCESS\")\n            \n            # Test read operation\n            saved_analysis = ResumeAnalysis.query.filter_by(candidate_name=\"Test Candidate\").first()\n            if saved_analysis:\n                print_status(\"‚úÖ Database read operation\", \"SUCCESS\")\n            else:\n                print_status(\"‚ùå Database read operation failed\", \"ERROR\")\n                return False\n            \n            # Clean up test data\n            db.session.delete(saved_analysis)\n            db.session.commit()\n            print_status(\"‚úÖ Database cleanup\", \"SUCCESS\")\n            \n        return True\n        \n    except Exception as e:\n        print_status(f\"‚ùå Database test failed: {e}\", \"ERROR\")\n        return False\n\ndef test_parser():\n    \"\"\"Test resume parser functionality\"\"\"\n    print_status(\"Testing resume parser...\", \"INFO\")\n    \n    try:\n        from utils.parser import ResumeParser\n        \n        parser = ResumeParser()\n        \n        # Test with sample text (simulating what would be extracted from a file)\n        sample_text = \"\"\"\n        JOHN DOE\n        Software Engineer\n        Email: john.doe@email.com\n        Phone: +1 (555) 123-4567\n        Location: San Francisco, CA\n        \n        EXPERIENCE:\n        Senior Python Developer - Tech Company (2020-2023)\n        Developed web applications using Python, Django, and React.\n        \n        EDUCATION:\n        Bachelor of Science in Computer Science - University (2016-2020)\n        \n        SKILLS:\n        Python, JavaScript, Django, React, SQL, AWS, Docker\n        \"\"\"\n        \n        personal_info = parser.parse_personal_info(sample_text)\n        skills = parser.extract_skills(sample_text)\n        experience = parser.extract_experience(sample_text)\n        education = parser.extract_education(sample_text)\n        \n        # Verify parsed data\n        if personal_info['name']:\n            print_status(\"‚úÖ Personal info parsing\", \"SUCCESS\")\n        else:\n            print_status(\"‚ö†Ô∏è Name not parsed\", \"WARNING\")\n            \n        if personal_info['email']:\n            print_status(\"‚úÖ Email parsing\", \"SUCCESS\")\n        else:\n            print_status(\"‚ö†Ô∏è Email not parsed\", \"WARNING\")\n            \n        if len(skills) > 0:\n            print_status(\"‚úÖ Skills extraction\", \"SUCCESS\")\n        else:\n            print_status(\"‚ùå Skills extraction failed\", \"ERROR\")\n            return False\n            \n        print_status(f\"üìä Found {len(skills)} skill categories\", \"INFO\")\n        print_status(f\"üìÖ Experience: {experience['total_years']} years\", \"INFO\")\n        print_status(f\"üéì Education: {education['highest_degree']}\", \"INFO\")\n        \n        return True\n        \n    except Exception as e:\n        print_status(f\"‚ùå Parser test failed: {e}\", \"ERROR\")\n        return False\n\ndef test_classifier():\n    \"\"\"Test ML classifier functionality\"\"\"\n    print_status(\"Testing ML classifier...\", \"INFO\")\n    \n    try:\n        from models.classifier import ResumeClassifier\n        \n        classifier = ResumeClassifier()\n        \n        # Test with sample data\n        test_text = \"\"\"\n        Python developer with 5 years experience in web development.\n        Skills include Python, Django, React, SQL, and AWS.\n        Bachelor's degree in Computer Science.\n        \"\"\"\n        \n        test_skills = {\n            'Programming': ['python', 'javascript'],\n            'Web Development': ['django', 'react'],\n            'Database': ['sql'],\n            'Cloud & DevOps': ['aws']\n        }\n        \n        test_experience = {'total_years': 5}\n        \n        status, department, score = classifier.classify_resume(test_text, test_skills)\n        fraud_score, findings = classifier.detect_fraud(test_text, test_skills, test_experience)\n        \n        print_status(f\"‚úÖ Classification: {status} | {department} | Score: {score}\", \"SUCCESS\")\n        print_status(f\"‚úÖ Fraud detection: {fraud_score}%\", \"SUCCESS\")\n        \n        if findings:\n            print_status(f\"üîç Fraud findings: {len(findings)}\", \"INFO\")\n        \n        return True\n        \n    except Exception as e:\n        print_status(f\"‚ùå Classifier test failed: {e}\", \"ERROR\")\n        return False\n\ndef test_file_operations():\n    \"\"\"Test file upload and processing operations\"\"\"\n    print_status(\"Testing file operations...\", \"INFO\")\n    \n    try:\n        # Create test uploads directory\n        test_upload_dir = \"test_uploads\"\n        os.makedirs(test_upload_dir, exist_ok=True)\n        \n        # Create a simple test file (simulating resume content)\n        test_file_path = os.path.join(test_upload_dir, \"test_resume.txt\")\n        with open(test_file_path, 'w', encoding='utf-8') as f:\n            f.write(\"Test resume content for file operations testing.\")\n        \n        if os.path.exists(test_file_path):\n            print_status(\"‚úÖ File creation\", \"SUCCESS\")\n            \n            # Test file reading\n            with open(test_file_path, 'r', encoding='utf-8') as f:\n                content = f.read()\n                if content:\n                    print_status(\"‚úÖ File reading\", \"SUCCESS\")\n            \n            # Clean up\n            os.remove(test_file_path)\n            os.rmdir(test_upload_dir)\n            print_status(\"‚úÖ File cleanup\", \"SUCCESS\")\n            \n            return True\n        else:\n            print_status(\"‚ùå File creation failed\", \"ERROR\")\n            return False\n            \n    except Exception as e:\n        print_status(f\"‚ùå File operations test failed: {e}\", \"ERROR\")\n        return False\n\ndef run_comprehensive_test():\n    \"\"\"Run all tests and provide summary\"\"\"\n    print(\"\\n\" + \"=\"*60)\n    print_status(\"üöÄ STARTING COMPREHENSIVE TEST SUITE\", \"INFO\")\n    print(\"=\"*60)\n    \n    test_results = []\n    \n    # Run all tests\n    test_results.append((\"Module Imports\", test_imports()))\n    test_results.append((\"Custom Modules\", test_custom_modules()))\n    test_results.append((\"Database\", test_database()))\n    test_results.append((\"Resume Parser\", test_parser()))\n    test_results.append((\"ML Classifier\", test_classifier()))\n    test_results.append((\"File Operations\", test_file_operations()))\n    \n    # Print summary\n    print(\"\\n\" + \"=\"*60)\n    print_status(\"üìä TEST SUMMARY\", \"INFO\")\n    print(\"=\"*60)\n    \n    passed = sum(1 for _, result in test_results if result)\n    total = len(test_results)\n    \n    for test_name, result in test_results:\n        status = \"‚úÖ PASS\" if result else \"‚ùå FAIL\"\n        color = \"SUCCESS\" if result else \"ERROR\"\n        print_status(f\"{status} - {test_name}\", color)\n    \n    print(\"\\n\" + \"=\"*60)\n    print_status(f\"Overall: {passed}/{total} tests passed\", \"SUCCESS\" if passed == total else \"WARNING\")\n    \n    if passed == total:\n        print_status(\"üéâ All tests passed! The application is ready to run.\", \"SUCCESS\")\n        print_status(\"üëâ Run: python app.py\", \"INFO\")\n    else:\n        print_status(\"‚ö†Ô∏è Some tests failed. Please check the errors above.\", \"WARNING\")\n        print_status(\"üîß Check requirements.txt and file structure.\", \"INFO\")\n    \n    print(\"=\"*60)\n    \n    return passed == total\n\nif __name__ == \"__main__\":\n    # Create necessary directories\n    os.makedirs(\"uploads\", exist_ok=True)\n    os.makedirs(\"data/trained_models\", exist_ok=True)\n    os.makedirs(\"static/css\", exist_ok=True)\n    \n    success = run_comprehensive_test()\n    sys.exit(0 if success else 1)","size_bytes":10853},"static/css/style.css":{"content":"/* Custom styles for Smart Resume Analyzer */\nbody {\n    background: linear-gradient(135deg, #1e3c72 0%, #2a5298 100%);\n    min-height: 100vh;\n    font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n}\n\n.navbar-brand {\n    font-weight: 700;\n    font-size: 1.5rem;\n}\n\n.upload-area {\n    border: 3px dashed #6c757d;\n    border-radius: 15px;\n    padding: 3rem;\n    text-align: center;\n    margin: 2rem 0;\n    transition: all 0.3s ease;\n    background: rgba(255, 255, 255, 0.05);\n    backdrop-filter: blur(10px);\n    cursor: pointer;\n}\n\n.upload-area:hover {\n    border-color: #0d6efd;\n    background: rgba(255, 255, 255, 0.1);\n    transform: translateY(-2px);\n}\n\n.upload-area.dragover {\n    border-color: #0d6efd;\n    background: rgba(255, 255, 255, 0.15);\n    transform: scale(1.02);\n}\n\n.score-card {\n    border-radius: 12px;\n    padding: 1.5rem;\n    margin: 0.5rem 0;\n    color: white;\n    text-align: center;\n    box-shadow: 0 4px 15px rgba(0, 0, 0, 0.2);\n    transition: transform 0.2s ease;\n}\n\n.score-card:hover {\n    transform: translateY(-3px);\n}\n\n.high-risk { \n    background: linear-gradient(45deg, #dc3545, #e83e8c);\n}\n\n.medium-risk { \n    background: linear-gradient(45deg, #ffc107, #fd7e14);\n    color: black;\n}\n\n.low-risk { \n    background: linear-gradient(45deg, #198754, #20c997);\n}\n\n.skill-badge { \n    margin: 0.2rem;\n    font-size: 0.85rem;\n}\n\n.feature-card {\n    background: rgba(255, 255, 255, 0.05);\n    border-radius: 10px;\n    border: 1px solid rgba(255, 255, 255, 0.1);\n    transition: all 0.3s ease;\n}\n\n.feature-card:hover {\n    transform: translateY(-5px);\n    background: rgba(255, 255, 255, 0.1);\n    box-shadow: 0 10px 25px rgba(0, 0, 0, 0.3);\n}\n\n.feature-card.fade-in {\n    animation: fadeInUp 0.6s ease-out;\n}\n\n@keyframes fadeInUp {\n    from {\n        opacity: 0;\n        transform: translateY(20px);\n    }\n    to {\n        opacity: 1;\n        transform: translateY(0);\n    }\n}\n\n.table-dark {\n    background: rgba(33, 37, 41, 0.9);\n    backdrop-filter: blur(10px);\n}\n\n.card {\n    background: rgba(33, 37, 41, 0.9);\n    backdrop-filter: blur(10px);\n    border: 1px solid rgba(255, 255, 255, 0.1);\n    transition: transform 0.2s ease;\n}\n\n.card:hover {\n    transform: translateY(-2px);\n}\n\n.progress {\n    background: rgba(255, 255, 255, 0.1);\n    border-radius: 10px;\n}\n\n.progress-bar {\n    border-radius: 10px;\n    transition: width 0.6s ease;\n}\n\n.report-content {\n    background-color: #2c3034;\n    border: 1px solid #495057;\n    border-radius: 5px;\n    padding: 15px;\n    color: #e9ecef;\n    font-family: 'Courier New', monospace;\n    font-size: 14px;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    max-height: 500px;\n    overflow-y: auto;\n}\n\n/* Responsive adjustments */\n@media (max-width: 768px) {\n    .upload-area {\n        padding: 2rem 1rem;\n        margin: 1rem 0;\n    }\n    \n    .score-card, .stat-card {\n        padding: 1rem;\n        margin: 0.25rem 0;\n    }\n    \n    .display-4 {\n        font-size: 2rem;\n    }\n    \n    .table-responsive {\n        font-size: 0.875rem;\n    }\n}\n\n/* Loading animations */\n.spinner-border {\n    animation: spinner-border 0.75s linear infinite;\n}\n\n@keyframes spinner-border {\n    to {\n        transform: rotate(360deg);\n    }\n}\n\n/* Custom scrollbar for webkit browsers */\n.report-content::-webkit-scrollbar {\n    width: 8px;\n}\n\n.report-content::-webkit-scrollbar-track {\n    background: #2c3034;\n    border-radius: 4px;\n}\n\n.report-content::-webkit-scrollbar-thumb {\n    background: #495057;\n    border-radius: 4px;\n}\n\n.report-content::-webkit-scrollbar-thumb:hover {\n    background: #6c757d;\n}","size_bytes":3579},"models/__init__.py":{"content":"","size_bytes":0},"app.py":{"content":"from flask import Flask, render_template, request, jsonify, send_file\nfrom flask_sqlalchemy import SQLAlchemy\nfrom datetime import datetime\nimport os\nimport json\nimport traceback\nimport logging\nfrom werkzeug.utils import secure_filename\n\n# Configure logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\napp = Flask(__name__)\napp.config['SQLALCHEMY_DATABASE_URI'] = 'sqlite:///app.db'\napp.config['SQLALCHEMY_TRACK_MODIFICATIONS'] = False\napp.config['UPLOAD_FOLDER'] = 'uploads'\napp.config['MAX_CONTENT_LENGTH'] = 16 * 1024 * 1024  # 16MB\napp.config['ALLOWED_EXTENSIONS'] = {'pdf', 'docx'}\n\ndb = SQLAlchemy(app)\n\nclass ResumeAnalysis(db.Model):\n    id = db.Column(db.Integer, primary_key=True)\n    filename = db.Column(db.String(200), nullable=False)\n    original_filename = db.Column(db.String(200))\n    upload_date = db.Column(db.DateTime, default=datetime.utcnow)\n    \n    candidate_name = db.Column(db.String(100))\n    candidate_email = db.Column(db.String(100))\n    candidate_phone = db.Column(db.String(20))\n    candidate_location = db.Column(db.String(100))\n    \n    work_experience = db.Column(db.Text)\n    education = db.Column(db.Text)\n    skills = db.Column(db.Text)\n    \n    classification_status = db.Column(db.String(20), default='Pending')\n    department = db.Column(db.String(50))\n    ranking_score = db.Column(db.Float, default=0.0)\n    experience_years = db.Column(db.Float, default=0.0)\n    education_level = db.Column(db.String(50))\n    \n    ai_generated_score = db.Column(db.Float, default=0.0)\n    date_consistency_score = db.Column(db.Float, default=0.0)\n    skill_authenticity_score = db.Column(db.Float, default=0.0)\n    overall_fraud_score = db.Column(db.Float, default=0.0)\n    \n    analysis_report = db.Column(db.Text)\n    processing_time = db.Column(db.Float)  # Processing time in seconds\n    \n    def to_dict(self):\n        return {\n            'id': self.id,\n            'filename': self.filename,\n            'original_filename': self.original_filename,\n            'candidate_name': self.candidate_name,\n            'candidate_email': self.candidate_email,\n            'candidate_phone': self.candidate_phone,\n            'candidate_location': self.candidate_location,\n            'classification_status': self.classification_status,\n            'department': self.department,\n            'ranking_score': self.ranking_score,\n            'experience_years': self.experience_years,\n            'education_level': self.education_level,\n            'ai_generated_score': self.ai_generated_score,\n            'overall_fraud_score': self.overall_fraud_score,\n            'analysis_report': self.analysis_report,\n            'skills': json.loads(self.skills) if self.skills else [],\n            'upload_date': self.upload_date.strftime('%Y-%m-%d %H:%M:%S'),\n            'processing_time': self.processing_time\n        }\n\n# Import components with error handling\ntry:\n    from utils.parser import ResumeParser\n    from models.classifier import ResumeClassifier\n    from models.ranker import ResumeRanker\n    logger.info(\"‚úÖ All modules imported successfully\")\nexcept ImportError as e:\n    logger.error(f\"‚ùå Import error: {e}\")\n    raise\n\n# Initialize components\nparser = ResumeParser()\nclassifier = ResumeClassifier()\nranker = ResumeRanker()\n\n# Create tables\nwith app.app_context():\n    try:\n        db.create_all()\n        logger.info(\"‚úÖ Database tables created successfully\")\n    except Exception as e:\n        logger.error(f\"‚ùå Database error: {e}\")\n\ndef allowed_file(filename):\n    \"\"\"Check if the file extension is allowed\"\"\"\n    return '.' in filename and \\\n           filename.rsplit('.', 1)[1].lower() in app.config['ALLOWED_EXTENSIONS']\n\ndef cleanup_old_files():\n    \"\"\"Clean up files older than 24 hours\"\"\"\n    try:\n        upload_dir = app.config['UPLOAD_FOLDER']\n        if not os.path.exists(upload_dir):\n            return\n        \n        current_time = datetime.now()\n        for filename in os.listdir(upload_dir):\n            file_path = os.path.join(upload_dir, filename)\n            if os.path.isfile(file_path):\n                file_time = datetime.fromtimestamp(os.path.getctime(file_path))\n                if (current_time - file_time).days > 1:  # Older than 1 day\n                    os.remove(file_path)\n                    logger.info(f\"üßπ Cleaned up old file: {filename}\")\n    except Exception as e:\n        logger.error(f\"‚ùå Error cleaning up files: {e}\")\n\n@app.route('/')\ndef index():\n    \"\"\"Main page\"\"\"\n    return render_template('index.html')\n\n@app.route('/health')\ndef health_check():\n    \"\"\"Health check endpoint\"\"\"\n    return jsonify({\n        'status': 'healthy',\n        'timestamp': datetime.utcnow().isoformat(),\n        'database': 'connected' if db.session.bind else 'disconnected'\n    })\n\n@app.route('/analyze', methods=['POST'])\ndef analyze_resume():\n    \"\"\"Analyze uploaded resume\"\"\"\n    start_time = datetime.now()\n    \n    try:\n        # Check if file was uploaded\n        if 'file' not in request.files:\n            return jsonify({'error': 'No file uploaded'}), 400\n        \n        file = request.files['file']\n        \n        # Check if file was selected\n        if file.filename == '':\n            return jsonify({'error': 'No file selected'}), 400\n        \n        # Validate file type\n        if not allowed_file(file.filename):\n            return jsonify({\n                'error': 'Invalid file type. Only PDF and DOCX files are allowed.',\n                'allowed_extensions': list(app.config['ALLOWED_EXTENSIONS'])\n            }), 400\n        \n        # Secure filename and save file\n        original_filename = secure_filename(file.filename)\n        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S_%f\")\n        filename = f\"{timestamp}_{original_filename}\"\n        file_path = os.path.join(app.config['UPLOAD_FOLDER'], filename)\n        \n        # Ensure upload directory exists\n        os.makedirs(app.config['UPLOAD_FOLDER'], exist_ok=True)\n        \n        file.save(file_path)\n        logger.info(f\"üìÅ File saved: {filename}\")\n        \n        # Extract text from file\n        file_ext = os.path.splitext(file.filename)[1].lower()\n        text = parser.extract_text(file_path, file_ext)\n        \n        if not text or len(text.strip()) < 50:\n            # Clean up the uploaded file\n            if os.path.exists(file_path):\n                os.remove(file_path)\n            return jsonify({\n                'error': 'Could not extract sufficient text from document. The file may be corrupted, scanned, or contain mostly images.'\n            }), 400\n        \n        logger.info(f\"üìù Extracted {len(text)} characters from resume\")\n        \n        # Parse resume information\n        personal_info = parser.parse_personal_info(text)\n        skills = parser.extract_skills(text)\n        experience = parser.extract_experience(text)\n        education = parser.extract_education(text)\n        \n        logger.info(f\"üë§ Candidate: {personal_info['name']} | Skills: {sum(len(s) for s in skills.values())}\")\n        \n        # Classify resume\n        status, department, ranking_score = classifier.classify_resume(text, skills)\n        \n        # Fraud detection\n        fraud_score, fraud_findings = classifier.detect_fraud(text, skills, experience)\n        \n        # Calculate processing time\n        processing_time = (datetime.now() - start_time).total_seconds()\n        \n        # Create comprehensive analysis report\n        analysis_report = f\"\"\"\nCOMPREHENSIVE RESUME ANALYSIS REPORT\n====================================\nGenerated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\nProcessing Time: {processing_time:.2f} seconds\n\nCANDIDATE INFORMATION:\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nName: {personal_info['name'] or 'Not specified'}\nEmail: {personal_info['email'] or 'Not specified'}\nPhone: {personal_info['phone'] or 'Not specified'}\nLocation: {personal_info['location'] or 'Not specified'}\n\nCLASSIFICATION RESULTS:\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nStatus: {status}\nRecommended Department: {department}\nRanking Score: {ranking_score:.1f}/100\nExperience: {experience['total_years']} years\nHighest Education: {education['highest_degree']}\n\nSKILLS ANALYSIS:\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nTotal Skills Categories: {len(skills)}\nTotal Skills: {sum(len(skills[cat]) for cat in skills)}\n\n{json.dumps(skills, indent=2, ensure_ascii=False)}\n\nFRAUD DETECTION:\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nOverall Fraud Score: {fraud_score}%\nFindings:\n{chr(10).join(['‚Ä¢ ' + finding for finding in fraud_findings]) if fraud_findings else '‚Ä¢ No significant fraud indicators detected'}\n\nRECOMMENDATION:\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n{'‚úÖ SHORTLIST - Strong candidate for ' + department + ' department' if status == 'Accepted' else '‚ùå REJECT - Does not meet minimum criteria'}\n\"\"\"\n\n        # Save analysis to database\n        analysis = ResumeAnalysis(\n            filename=filename,\n            original_filename=original_filename,\n            candidate_name=personal_info['name'],\n            candidate_email=personal_info['email'],\n            candidate_phone=personal_info['phone'],\n            candidate_location=personal_info['location'],\n            work_experience=json.dumps(experience, ensure_ascii=False),\n            education=json.dumps(education, ensure_ascii=False),\n            skills=json.dumps(skills, ensure_ascii=False),\n            classification_status=status,\n            department=department,\n            ranking_score=ranking_score,\n            experience_years=experience['total_years'],\n            education_level=education['highest_degree'],\n            overall_fraud_score=fraud_score,\n            analysis_report=analysis_report,\n            processing_time=processing_time\n        )\n        \n        db.session.add(analysis)\n        db.session.commit()\n        \n        logger.info(f\"‚úÖ Analysis completed: {status} | {department} | Score: {ranking_score}\")\n        \n        # Return analysis results\n        response_data = analysis.to_dict()\n        response_data['processing_time'] = processing_time\n        response_data['text_length'] = len(text)\n        response_data['total_skills'] = sum(len(skills[cat]) for cat in skills)\n        \n        return jsonify(response_data)\n        \n    except Exception as e:\n        logger.error(f\"‚ùå Analysis failed: {str(e)}\")\n        logger.error(traceback.format_exc())\n        \n        # Clean up uploaded file if it exists\n        try:\n            if 'file_path' in locals() and os.path.exists(file_path):\n                os.remove(file_path)\n        except:\n            pass\n        \n        return jsonify({\n            'error': f'Analysis failed: {str(e)}',\n            'details': 'Please check the file format and try again.'\n        }), 500\n\n@app.route('/history')\ndef history():\n    \"\"\"Display analysis history\"\"\"\n    try:\n        analyses = ResumeAnalysis.query.order_by(ResumeAnalysis.upload_date.desc()).all()\n        return render_template('history.html', analyses=analyses)\n    except Exception as e:\n        logger.error(f\"‚ùå History error: {e}\")\n        return render_template('history.html', analyses=[])\n\n@app.route('/dashboard')\ndef dashboard():\n    \"\"\"Display analytics dashboard\"\"\"\n    try:\n        analyses = ResumeAnalysis.query.all()\n        total = len(analyses)\n        accepted = len([a for a in analyses if a.classification_status == 'Accepted'])\n        \n        # Department distribution\n        departments = {}\n        for analysis in analyses:\n            if analysis.department:\n                departments[analysis.department] = departments.get(analysis.department, 0) + 1\n        \n        # Average scores\n        avg_ranking = np.mean([a.ranking_score for a in analyses]) if analyses else 0\n        avg_fraud = np.mean([a.overall_fraud_score for a in analyses]) if analyses else 0\n        \n        return render_template('dashboard.html',\n                             total_resumes=total,\n                             accepted=accepted,\n                             rejected=total - accepted,\n                             departments=departments,\n                             analyses=analyses,\n                             avg_ranking=avg_ranking,\n                             avg_fraud=avg_fraud)\n    except Exception as e:\n        logger.error(f\"‚ùå Dashboard error: {e}\")\n        return render_template('dashboard.html',\n                             total_resumes=0,\n                             accepted=0,\n                             rejected=0,\n                             departments={},\n                             analyses=[],\n                             avg_ranking=0,\n                             avg_fraud=0)\n\n@app.route('/api/shortlist')\ndef get_shortlisted():\n    \"\"\"API endpoint for shortlisted candidates\"\"\"\n    try:\n        accepted_candidates = ResumeAnalysis.query.filter_by(classification_status='Accepted').all()\n        candidates_data = [candidate.to_dict() for candidate in accepted_candidates]\n        top_candidates = ranker.get_top_candidates_all_departments(candidates_data, top_n=5)\n        return jsonify(top_candidates)\n    except Exception as e:\n        logger.error(f\"‚ùå Shortlist API error: {e}\")\n        return jsonify({'error': 'Failed to get shortlisted candidates'}), 500\n\n@app.route('/api/analyses')\ndef get_analyses():\n    \"\"\"API endpoint for all analyses\"\"\"\n    try:\n        analyses = ResumeAnalysis.query.order_by(ResumeAnalysis.upload_date.desc()).all()\n        return jsonify([analysis.to_dict() for analysis in analyses])\n    except Exception as e:\n        logger.error(f\"‚ùå Analyses API error: {e}\")\n        return jsonify({'error': 'Failed to get analyses'}), 500\n\n@app.route('/analysis/<int:analysis_id>')\ndef get_analysis(analysis_id):\n    \"\"\"Get specific analysis by ID\"\"\"\n    try:\n        analysis = ResumeAnalysis.query.get_or_404(analysis_id)\n        return jsonify(analysis.to_dict())\n    except Exception as e:\n        logger.error(f\"‚ùå Analysis {analysis_id} error: {e}\")\n        return jsonify({'error': 'Analysis not found'}), 404\n\n@app.route('/delete/<int:analysis_id>', methods=['DELETE'])\ndef delete_analysis(analysis_id):\n    \"\"\"Delete analysis by ID\"\"\"\n    try:\n        analysis = ResumeAnalysis.query.get_or_404(analysis_id)\n        \n        # Delete associated file\n        file_path = os.path.join(app.config['UPLOAD_FOLDER'], analysis.filename)\n        if os.path.exists(file_path):\n            os.remove(file_path)\n        \n        db.session.delete(analysis)\n        db.session.commit()\n        \n        logger.info(f\"üóëÔ∏è Deleted analysis: {analysis_id}\")\n        return jsonify({'message': 'Analysis deleted successfully'})\n    except Exception as e:\n        logger.error(f\"‚ùå Delete error: {e}\")\n        return jsonify({'error': 'Failed to delete analysis'}), 500\n\n# Error handlers\n@app.errorhandler(404)\ndef not_found_error(error):\n    return jsonify({'error': 'Endpoint not found'}), 404\n\n@app.errorhandler(500)\ndef internal_error(error):\n    return jsonify({'error': 'Internal server error'}), 500\n\n@app.errorhandler(413)\ndef too_large(error):\n    return jsonify({'error': 'File too large. Maximum size is 16MB.'}), 413\n\nif __name__ == '__main__':\n    # Ensure required directories exist\n    os.makedirs('uploads', exist_ok=True)\n    os.makedirs('data/trained_models', exist_ok=True)\n    \n    # Clean up old files on startup\n    cleanup_old_files()\n    \n    print(\"üöÄ Starting Smart Resume Analyzer...\")\n    print(\"üìä Dashboard: http://localhost:5000\")\n    print(\"üìà API Health: http://localhost:5000/health\")\n    print(\"üîç Analysis History: http://localhost:5000/history\")\n    print(\"‚ö° Ready to analyze resumes!\")\n    print(\"-\" * 50)\n    \n    app.run(debug=True, host='0.0.0.0', port=5000)","size_bytes":15827}},"version":2}